{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import time\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "texts = [clean_text(text) for text in newsgroups.data[:5000]]\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    max_features=3000,\n",
        "    stop_words='english',\n",
        "    min_df=5,\n",
        "    max_df=0.75,\n",
        "    token_pattern=r'\\b[a-zA-Z]{3,}\\b'\n",
        ")\n",
        "X = vectorizer.fit_transform(texts)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "V = len(vocab)\n",
        "\n",
        "M = X.shape[0]\n",
        "rows, cols = X.nonzero()\n",
        "counts = X.data.astype(int)\n",
        "\n",
        "all_words = []\n",
        "all_doc_ids = []\n",
        "for i in range(len(rows)):\n",
        "    all_words.extend([cols[i]] * counts[i])\n",
        "    all_doc_ids.extend([rows[i]] * counts[i])\n",
        "\n",
        "all_words = np.array(all_words, dtype=np.int32)\n",
        "all_doc_ids = np.array(all_doc_ids, dtype=np.int32)\n",
        "W = len(all_words)\n",
        "\n",
        "K = 20\n",
        "alpha = 0.1\n",
        "beta = 0.01\n",
        "n_iter = 70\n",
        "beta_sum = beta * V\n",
        "\n",
        "n_dk = np.zeros((M, K), dtype=np.int32)\n",
        "n_kw = np.zeros((K, V), dtype=np.int32)\n",
        "n_k = np.zeros(K, dtype=np.int32)\n",
        "\n",
        "np.random.seed(42)\n",
        "z = np.random.randint(0, K, size=W, dtype=np.int32)\n",
        "\n",
        "for i in range(W):\n",
        "    doc_id = all_doc_ids[i]\n",
        "    word_id = all_words[i]\n",
        "    topic = z[i]\n",
        "    n_dk[doc_id, topic] += 1\n",
        "    n_kw[topic, word_id] += 1\n",
        "    n_k[topic] += 1\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for iteration in range(n_iter):\n",
        "    order = np.random.permutation(W)\n",
        "    for idx in order:\n",
        "        doc_id = all_doc_ids[idx]\n",
        "        word_id = all_words[idx]\n",
        "        old_topic = z[idx]\n",
        "\n",
        "        n_dk[doc_id, old_topic] -= 1\n",
        "        n_kw[old_topic, word_id] -= 1\n",
        "        n_k[old_topic] -= 1\n",
        "\n",
        "        p = (n_dk[doc_id, :] + alpha) * (n_kw[:, word_id] + beta) / (n_k + beta_sum)\n",
        "        p_sum = p.sum()\n",
        "\n",
        "        if p_sum > 0:\n",
        "            p /= p_sum\n",
        "            new_topic = np.random.choice(K, p=p)\n",
        "        else:\n",
        "            new_topic = np.random.randint(0, K)\n",
        "\n",
        "        z[idx] = new_topic\n",
        "        n_dk[doc_id, new_topic] += 1\n",
        "        n_kw[new_topic, word_id] += 1\n",
        "        n_k[new_topic] += 1\n",
        "\n",
        "    if (iteration + 1) % 10 == 0:\n",
        "        print(f\"Итерация {iteration + 1}/{n_iter}\")\n",
        "\n",
        "print(f\"\\nВремя выполнения: {time.time() - start_time:.1f} сек\")\n",
        "\n",
        "noise_words = {\n",
        "    'wa', 'ha', 'doe', 'would', 'one', 'get', 'like', 'know', 'time', 'people',\n",
        "    'say', 'think', 'just', 'don', 'good', 'way', 'really', 'right', 'going',\n",
        "    'make', 'use', 'used', 'new', 'year', 'years', 'day', 'days', 'went',\n",
        "    'said', 'did', 'told', 'saw', 'didn', 'left', 'does', 'doesn', 've', 'll'\n",
        "}\n",
        "\n",
        "def is_good_word(word):\n",
        "    if len(word) < 3:\n",
        "        return False\n",
        "    if word in noise_words:\n",
        "        return False\n",
        "    if any(char.isdigit() for char in word) and len(word) <= 4:\n",
        "        return False\n",
        "    if re.match(r'^[a-z]{1,2}\\d+', word) or re.match(r'^\\d+[a-z]{1,2}$', word):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "phi = (n_kw + beta) / (n_k[:, np.newaxis] + beta_sum)\n",
        "\n",
        "print(\"\\nТоп-10 слов по 20 темам:\")\n",
        "for k in range(K):\n",
        "    top_indices = np.argsort(phi[k])[-25:][::-1]\n",
        "    top_words_all = [vocab[i] for i in top_indices]\n",
        "\n",
        "    filtered_words = []\n",
        "    for word in top_words_all:\n",
        "        if is_good_word(word):\n",
        "            filtered_words.append(word)\n",
        "        if len(filtered_words) >= 10:\n",
        "            break\n",
        "\n",
        "    if len(filtered_words) < 6:\n",
        "        filtered_words = [w for w in top_words_all[:15] if len(w) >= 3][:10]\n",
        "\n",
        "    if len(filtered_words) < 5:\n",
        "        filtered_words = top_words_all[:10]\n",
        "\n",
        "    print(f\"Тема {k+1:2d}: {', '.join(filtered_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wag4Ct9Z_C4m",
        "outputId": "4fb82a80-528e-4ad9-a329-92d6dbd49d02"
      },
      "id": "wag4Ct9Z_C4m",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация 10/70\n",
            "Итерация 20/70\n",
            "Итерация 30/70\n",
            "Итерация 40/70\n",
            "Итерация 50/70\n",
            "Итерация 60/70\n",
            "Итерация 70/70\n",
            "\n",
            "Время выполнения: 663.7 сек\n",
            "\n",
            "Топ-10 слов по 20 темам:\n",
            "Тема  1: windows, dos, files, using, file, program, memory, package, problem, need\n",
            "Тема  2: god, jesus, law, believe, world, life, matthew, christian, want, come\n",
            "Тема  3: window, display, widget, application, set, value, using, data, null, color\n",
            "Тема  4: launch, national, april, high, satellite, center, cost, york, washington, low\n",
            "Тема  5: file, send, output, entry, line, program, check, read, article, list\n",
            "Тема  6: true, question, bible, christians, things, faith, church, argument, truth, man\n",
            "Тема  7: available, image, edu, graphics, ftp, version, software, sun, pub, code\n",
            "Тема  8: max, giz, bhj, bxn, qax, chz, rlk, nrhj, tct, fpl\n",
            "Тема  9: space, science, nasa, data, current, systems, ground, theory, large, design\n",
            "Тема 10: internet, information, privacy, anonymous, public, mail, list, news, email, service\n",
            "Тема 11: israel, evidence, state, israeli, land, war, rights, human, greek, force\n",
            "Тема 12: gun, police, law, guns, control, weapons, firearms, crime, home, court\n",
            "Тема 13: armenian, turkish, armenians, jews, university, turkey, jewish, soviet, genocide, health\n",
            "Тема 14: key, chip, bit, encryption, clipper, keys, data, phone, using, government\n",
            "Тема 15: better, want, thing, things, got, long, course, quite, need, short\n",
            "Тема 16: thanks, bike, post, dod, want, looking, mail, read, getting, probably\n",
            "Тема 17: game, play, team, games, season, period, players, power, got, second\n",
            "Тема 18: government, president, work, administration, support, american, states, money, program, clinton\n",
            "Тема 19: drive, scsi, card, price, hard, ram, disk, sale, work, thanks\n",
            "Тема 20: car, point, water, little, come, tell, believe, isn, wrong\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}